WEBVTT
Kind: captions
Language: ar

00:00:01.745 --> 00:00:02.745
 

00:00:04.755 --> 00:00:05.755
 

00:00:09.075 --> 00:00:10.075
 

00:00:24.905 --> 00:00:28.105
أعزائي المشاهدين السلام عليكم ورحمة الله وبركاتة
 أهلا بكم في حلقة جديدة

00:00:28.105 --> 00:00:29.680
من برنامج الدحيح

00:00:29.680 --> 00:00:30.860
سنة 1997

00:00:31.120 --> 00:00:33.380
كان واحد من اهم المباريات في تاريخ البشرية

00:00:34.500 --> 00:00:36.500
غاري كاسباروف هو واحد من اعظم لاعبي الشطرنج

00:00:36.580 --> 00:00:37.240
الي جم (الذين مروا)  في التاريخ

00:00:37.280 --> 00:00:38.400
كاسباروف مش (ليس) عاديا

00:00:38.400 --> 00:00:42.900
سنة ال1978,كان اصغر لاعب يصل لبطولة الاتحاد السوفيتي في الشطرنج

00:00:42.900 --> 00:00:44.220
كان عنده (عمره) 15 سنة

00:00:44.220 --> 00:00:46.900
سنة 1983, و هو عنده (عمره) 19 سنة

00:00:46.920 --> 00:00:47.760
حاز على المركز الثاني

00:00:48.160 --> 00:00:49.880
المركز الأول كان الأسطورة

00:00:50.080 --> 00:00:51.040
كاربوف

00:00:51.180 --> 00:00:52.040
و في سنة 1984,بقى (أصبح) كاسباروف

00:00:52.040 --> 00:00:52.720
الأول على العالم

00:00:52.880 --> 00:00:55.340
سنة 1985,كاسباروف اصبح أصغر بطل في العالم.

00:00:55.340 --> 00:00:57.340
كسر أرقاما قياسية بعشرات السنين

00:00:57.340 --> 00:00:58.500
تاريخ كاسباروف مشرف

00:00:58.500 --> 00:01:00.900
و لو هناك شخص يمكن له تمثيل البشرية

00:01:01.100 --> 00:01:02.520
امام عملاق 2 متر

00:01:02.540 --> 00:01:03.480
عنده قدرة جبارة

00:01:03.480 --> 00:01:06.020
ب 200 مليون حسبة (عملية حسابية) في الثانية الواحدة

00:01:06.020 --> 00:01:08.020
فما فيش (لا يوجد غير) كاسباروف

00:01:08.900 --> 00:01:12.020
غاري كاسباروف في صراع مع كمبيوتر(حاسوب)  من صناعة IBM,

00:01:12.020 --> 00:01:13.000
اسمه ديب بلوي ( الأزرق الداكن)

00:01:13.000 --> 00:01:14.980
و دا (هذا) في رأيي أهم ماتش (مبارة)  في تاريخ البشرية

00:01:14.980 --> 00:01:16.980
ديب بلو دا (هذا) بكل منصاته و قوته 2 طن

00:01:16.980 --> 00:01:19.420
2 طن مصمم خصيصا للعب الشطرنج

00:01:19.420 --> 00:01:21.400
ما بيعملش (لا يعمل) حاجة (شيء) في حياته غير أنه

00:01:21.400 --> 00:01:23.120
يلعب قدام (امام) مخ بالكتير اوي (على أقصى حد)

00:01:23.120 --> 00:01:23.640
وزنه 2 كيلو

00:01:23.640 --> 00:01:25.240
و ليس مصمما فقط للعب الشطرنج ,

00:01:25.240 --> 00:01:26.760
(إنما) بعمل مئات الحاجات (الأشياء) المختلة

00:01:26.760 --> 00:01:27.960
المقارنة ممكن تبان (تبدو) ظالمة

00:01:28.100 --> 00:01:30.180
بس دي مش أول ماتش (مبارة) قبل كده (ذلك) هزم جهاز IBM

00:01:30.320 --> 00:01:32.620
و أبهر العالم! و حافظ على صورة البشرية

00:01:32.720 --> 00:01:33.360
قدام (أمام) اختراعتها

00:01:33.360 --> 00:01:35.160
بس (لكن) المرة دي (هذه المرة) التوقعات عالية

00:01:35.160 --> 00:01:36.860
مهندسو ال IBM تعلموا من أخطائهم

00:01:36.860 --> 00:01:38.840
في الماتش (المبارة) السابقة

00:01:38.840 --> 00:01:40.900
و في أمل انه "Deep blue" يغلب كاسباروف

00:01:40.900 --> 00:01:42.600
هل يا ترى "Deep blue" هيعملها و يكسب؟!

00:01:42.740 --> 00:01:44.300
و يبقى (يصبح) أول كمبيوتر (حاسوب)  في التاريخ

00:01:44.420 --> 00:01:45.540
يكسب (يغلب) بطل شطرنج

00:01:45.540 --> 00:01:46.620
و مش (و ليس) بطلا عاديا دا (هذا) أهم بطل

00:01:46.720 --> 00:01:47.220
في تاريخ اللعبة

00:01:47.560 --> 00:01:49.100
أول ماتش من ستة

00:01:49.100 --> 00:01:50.420
كاسباروف يكسب (يربح) بسهولة

00:01:50.420 --> 00:01:51.920
و ده يديله (هذا يعطيه) ثقة كبيرة بالنفس
 أوي!

00:01:51.920 --> 00:01:53.700
ابتدأ (بدأ) بالإحساس انه (خلاص!).
فهم كيفية تفكير الحاسوب

00:01:53.700 --> 00:01:55.740
ثاني مباراة, الدنيا اتقلبت 
(انقلبت المعادلة)

00:01:55.740 --> 00:01:57.100
ديب بلو يكسب  بحركة خبيثة جدا

00:01:57.100 --> 00:01:59.820
شف هناك في عصفور!

00:02:02.720 --> 00:02:03.220
لا!

00:02:03.880 --> 00:02:06.360
كاسباروف افتكر (ظن) انه فهم
طريقة لعب الحاسوب و

00:02:06.360 --> 00:02:07.780
و لان الحاسوب كان يلعب بطريقة

00:02:07.920 --> 00:02:10.740
أنه طالما جاله  فرصة  انه ياكل يبقى ياكل 
(كلما سنحت له الفرصة ان يطيح ببيدق لا يضيعها )

00:02:10.980 --> 00:02:12.640
فهو بدأ يحطله (يضع له)  طعم

00:02:12.640 --> 00:02:14.060
عشان  يؤكَله(لكي يجعله ياخذ بيدقا)

00:02:14.060 --> 00:02:16.420
لكن في حركة صادمة جدًا من الحاسوب

00:02:16.560 --> 00:02:18.220
قرر ان ما يخدش (لا يأكل) الطعم

00:02:18.640 --> 00:02:21.680
التصرف الذي صدر عن الحاسوب
  عقلاني جدا!

00:02:21.680 --> 00:02:23.600
زي  ما تكون جعان  و بايدك تفاحة
(مثل ان تكون جائعا و في يدك تفاحة)

00:02:24.000 --> 00:02:27.840
بس بدل ما تاكلها تستنى الغدا بعدين تعالي بيها! 
(لكن بدلا ان تأكلاها, انظر الغداء و ائتني بها!)

00:02:27.920 --> 00:02:29.060
بس الحركة دي بس
(الحركة هذه فقط)

00:02:29.220 --> 00:02:30.460
تشل كاسباروف فكريا

00:02:30.640 --> 00:02:32.120
خلال الأربع مباريات القادمة

00:02:32.120 --> 00:02:33.320
هنا يبتدي  (يبدأ) يحصل وسوسة!

00:02:33.320 --> 00:02:34.780
و يبدأ بالشك بفريق IBM

00:02:34.860 --> 00:02:35.840
على حسب كلام كاسباروف

00:02:35.840 --> 00:02:38.120
(هذه) الحركة دي  لا يمكن حد  يعملها (لاحد فعلها)
الا إذا كان انسانا

00:02:38.120 --> 00:02:39.660
و فضل الوسواس شغال (استمر الوسواس)

00:02:39.660 --> 00:02:41.040
و هنا كانت نقطة ضعف الإنسان

00:02:41.040 --> 00:02:42.000
العامل النفسي

00:02:42.000 --> 00:02:44.000
مخنا جبار
 بس (لكن) احيانًا يعطل نفسه

00:02:44.360 --> 00:02:46.220
كاسباروف بدأ بالإحساس ان IBM يغشون

00:02:46.220 --> 00:02:48.480
بدأ أحساسه أن هنالك حالات تجسس تحصل على غرفته

00:02:48.580 --> 00:02:49.740
كاسباروف بدأ احساسه أنه

00:02:49.920 --> 00:02:51.920
ليس انه يواجه حاسوبا  ذا قدرة تنبؤيه

00:02:52.120 --> 00:02:54.480
ممكن ان تصل ل 78 حركة قادمة فحسب

00:02:54.640 --> 00:02:57.740
و 8 مهندسين يغيروا الخوارزميات بوجه كل مباراة!

00:02:57.840 --> 00:03:00.880
دا كمان (و ايضا) يمكن يكون هناك لاعب
شطرنج يساعدهم!

00:03:00.880 --> 00:03:02.420
لم يعد قادرا على التركيز

00:03:02.520 --> 00:03:03.720
3  مباريات يتعادل

00:03:03.720 --> 00:03:05.940
مباراة الأخيرة

00:03:06.100 --> 00:03:08.140
يخسر

00:03:08.200 --> 00:03:09.860
كاسباروف لأول مرة في تاريخه

00:03:09.860 --> 00:03:12.360
يخسر مباراة في اقل من 19 حركة

00:03:12.360 --> 00:03:13.760
أول مرة يخسر مباراة

00:03:13.760 --> 00:03:16.480
من (امام) كائن حي او مش حي من سنة 85

00:03:16.480 --> 00:03:17.560
كاسباروف خسر الماتش ده (المبارة هذه)

00:03:17.560 --> 00:03:18.580
و البشرية خسرت معه

00:03:18.580 --> 00:03:20.160
البشرية ما عدتشي (لم تعد) محتكرة الذكاء

00:03:20.160 --> 00:03:21.920
دا (ذلك ان)  البشرية بذكائها

00:03:21.920 --> 00:03:23.300
خلقت ذكاء يغلب ذكائها

00:03:23.320 --> 00:03:24.180
ايه الغباء ده؟!
(ما هذا الغباء!)

00:03:24.180 --> 00:03:27.100
الماتشي ده  (هذه المباراة) كان كافي
يفتح ابواب جهنم على البشرية

00:03:27.100 --> 00:03:29.100
(أصل) طالما  غلب احسن لاعب شطرنج في التاريخ

00:03:29.120 --> 00:03:30.700
يبقى يغلبش احسن دكاترة؟؟!
(لما لا يغلب احسن الاطباء؟!)

00:03:30.700 --> 00:03:31.860
يبقى يغلبش احسن مهندسين؟!
(لما لا يغلب احسن المهندسين؟!)

00:03:31.860 --> 00:03:33.140
يبقى يغلبش احسن علماء
(لما لا يتغلب احسن العلماء؟!)

00:03:33.140 --> 00:03:34.360
ليه ما يغلبش احسن فنانين؟!
(لما لا يتغلب احسن الفنانين؟!)

00:03:34.700 --> 00:03:36.080
الفكرة ان المبرمجين النهارده (اليوم)

00:03:36.080 --> 00:03:37.400
عندهم كم من المعلومات هائل!

00:03:37.540 --> 00:03:39.520
احنا بقينا نقعد (نحن اصحبنا نمضي) أوقات طويلة على أجهزتنها

00:03:39.520 --> 00:03:40.020
و ده مش بروح كدا
(هذا لا يذهب هباء!)

00:03:40.020 --> 00:03:40.900
مش كل حاجة بتتنسي
(لا ينسى كل شيء)

00:03:40.900 --> 00:03:42.180
في سيرفيرات ماسكة ورقة و قلم
(هناك خوادم تحمل ورقة و قلم)

00:03:42.180 --> 00:03:43.240
و تكتب كل حاجة (شيء) تفعله

00:03:43.240 --> 00:03:44.740
هيبقى (سيصبح) عندنا ما يسمى بال Big data

00:03:44.740 --> 00:03:46.080
معلومات كثيرة
كثيرة جدا!

00:03:46.080 --> 00:03:48.840
و زمان كمان احنا كنا السيرفيرات دي بنقلها تعمل ايه
(و كنا نلقن الخوادم ماذا ستفعل بالمعلومات في الماضي)

00:03:49.100 --> 00:03:52.100
النهاردة بتتعلم ازاي تتعلم!
(اليوم هي تتعلم كيف تتعلم؟!)

00:03:52.100 --> 00:03:54.340
و ممكن كمان ازي تتعلم ازاي تتعلم!
(ممكن أيضا ان تتعلم كيفية كيفية التعلم!)

00:03:54.340 --> 00:03:56.060
و بقى (اصبح) عندها معلومات كثيرة

00:03:56.120 --> 00:03:57.480
مع كم الملومات دي (هذه)

00:03:57.480 --> 00:03:59.620
الكمبيوترات بقت تتعلم ايه الحاجات تجبلك
(بدأت الحواسيب بتعلم المحتوى المراد لديك)

00:03:59.780 --> 00:04:02.200
سواء كانت أفلام (أو) فيديوهات أو أصدقاء

00:04:02.200 --> 00:04:03.740
كل ده (هذا) رجوعا بالزمن

00:04:03.740 --> 00:04:06.680
في الستينيات العلماء كانوا عايزين يفهموا  المخ بفكر ازاي
(كان العلماء يريدون فهم كيفية تفكير المخ)

00:04:06.680 --> 00:04:09.640
فيقوموا رايحين للخلايا و يفهموا الخلايا دي بتشتغل ازاي
(فيذهبون للخلايا و يشاهدوا كيفية عمل الخلايا)

00:04:09.640 --> 00:04:12.360
و ابتدأ يحصل تاسيس لحاجة اسمها Neural networks 
(و بدأ بتأسيس لمشروع اسمه "شبكات الاعصاب")

00:04:12.360 --> 00:04:15.400
فيبقى (فيصبح) عندنا حاسوب يتعلم تقريبا زي (مثل) تعلم المخ

00:04:15.400 --> 00:04:16.735
عملوا حاجة اسمها  Perceptor "المدرك"

00:04:16.735 --> 00:04:19.735
كانت "عاملة" طفرة قادرة على تفريق بين المثلثات و المربعات

00:04:19.740 --> 00:04:21.620
و على الرغم من ان هذا يعتبر امرا تافها اليوم

00:04:21.620 --> 00:04:23.080
الا ان هذا هو جهاز حاسوب

00:04:23.080 --> 00:04:25.220
يجرب و يخطئ و يتعلم من غلطه

00:04:25.220 --> 00:04:26.580
دي (التجربة) كانت حاجة في غاية الثورية

00:04:26.580 --> 00:04:29.200
كانك خلفت (انجبت) طفلا, و هذا الطفل ييمشي و يتعلم من  تلقاء نفسه

00:04:29.440 --> 00:04:30.960
نجن لم نقم بتعليمه اي شيء

00:04:30.960 --> 00:04:32.820
احنا بس علمناه ازاي يتعلم 
(نحن فقط علمناه كيفية التعلم )

00:04:32.840 --> 00:04:33.700
هو بقى يذاكر لوحده

00:04:33.740 --> 00:04:34.760
لما يلاعب (يغلب) ديب بلو كاسباروف

00:04:34.760 --> 00:04:37.300
ديب بلو كان مذاكر(دارس) اكثر من 
700 الف مباراة

00:04:37.680 --> 00:04:40.980
غوغل ترانزلات في 2005,
 ذاكر(درس) اكثر من 200 مليار كلمة

00:04:40.980 --> 00:04:42.580
من وثائق الأمم المتحدة اللي (التي) كانت مترجمة

00:04:42.580 --> 00:04:44.580
فكان يشوف (يشاهد) كيف  كانت الكلمة مترجمة (ازاي)

00:04:44.580 --> 00:04:45.940
و يحفظها و يذاكرها (يدرسها)

00:04:46.160 --> 00:04:48.080
بحيث انه لما يجيه (تاتيه) حاجة جديدة يقدر هو يترجمها

00:04:48.080 --> 00:04:49.220
كل ده عشان (هذا) ليتعلم الترجمة

00:04:49.220 --> 00:04:50.860
معلش! بس الأرقام دي كانت زمان
(عفوا لكن هذه الارقام كانت منذ زمن)

00:04:50.860 --> 00:04:52.420
بنقدر نعمل ايه دلوقتي؟

00:04:52.420 --> 00:04:53.820
أجهزتنا بتقدر تعمل ايه دلوقتي؟!
(ماذا بسوعنا أجهزتنا فعله الان؟!)

00:04:53.820 --> 00:04:54.640
اخرها ايه (بماذا سينتهي الأمر؟)

00:04:54.640 --> 00:04:56.500
أولا سنة 2016
شركة اسمها Deep mind

00:04:56.500 --> 00:04:57.900
بتعمل (تصنع) جهازا

00:04:57.900 --> 00:04:59.820
يكسب بطولة العالم في لعبة 
اسمها GO

00:04:59.820 --> 00:05:02.000
فيها حركات اكثر من الشطرنج بمراحل

00:05:02.120 --> 00:05:04.220
يوم ما كسب الجهاز طبعا احنا ما سمعناش حاجة اوي
(لم نسمع الكثير!)

00:05:04.220 --> 00:05:05.640
لكن  برا الدنيا كانت مولعة (مشتعلة)

00:05:05.660 --> 00:05:07.160
كانت حدث تاريخي مثل  مباراة كاسباروف

00:05:07.160 --> 00:05:08.420
سنة 2012,

00:05:08.420 --> 00:05:12.700
تقريبا 240 شركة حصلوا على مبلغ
 750 مليون دولار

00:05:12.700 --> 00:05:14.340
عشان يعملوا محامي
(لكي يصنعوا محاميا!)

00:05:14.360 --> 00:05:15.920
مش بالضبط كدا 
(ليس بالضبط)

00:05:15.920 --> 00:05:18.780
لكن اليوم هناك روبوتات على مقدرة أن تصنع 
نسبة من عمل المحامين.

00:05:18.780 --> 00:05:19.940
الذي يعتبر أمرا صعبا للغاية

00:05:19.940 --> 00:05:20.740
عن طريق الذكاء الاصطناعي

00:05:20.740 --> 00:05:24.280
تستطيع بعض الأجهزة تحديد المهم من الأوراق من غيره 
في القضية

00:05:24.280 --> 00:05:26.020
و بحسب دراسة أجريت في جامعة نورث كارلونيا

00:05:26.200 --> 00:05:29.900
التقنية الحالية تستطيع إتمام 13% من عمل المحامين

00:05:29.900 --> 00:05:30.880
و في بعض المهام (تاسكات)

00:05:30.880 --> 00:05:32.680
وصل العدد الى 96%

00:05:32.680 --> 00:05:34.200
انأ احس انك لا تشعر بانبهار تجاه هذا الكلام

00:05:34.200 --> 00:05:35.820
ما رأيك في شيء مثل نيوتن على سبيل المثال؟!

00:05:35.820 --> 00:05:36.440
معقد!

00:05:36.440 --> 00:05:37.140
غير مقصودة

00:05:37.140 --> 00:05:39.420
المهم يعني انه في 2009 في ورقة (مقال) منشروة في الSCIENCE

00:05:39.420 --> 00:05:40.700
مجموعة من العلماء

00:05:40.820 --> 00:05:42.840
عملوا (صنعوا) برنامج اكتشف قوانين نيوتن

00:05:42.840 --> 00:05:44.520
يا فرحتي! طب ما احنا عرفنيها!
(نحن نعلم بها من قبل!)

00:05:44.520 --> 00:05:45.280
لا يا بابا!

00:05:45.280 --> 00:05:48.360
فكرة انك تبص (تنظر) على حاجة و تطلع (تستخرج) معادلات توصفها

00:05:48.360 --> 00:05:49.440
دي مش حاجة سهلة!

00:05:49.440 --> 00:05:52.740
انت تتحدث عن جهاز درس بعض الحركات و استنتج لها قانون!

00:05:52.740 --> 00:05:55.340
المفروض نصفق له!

00:05:55.620 --> 00:05:57.020
في سنة 2016

00:05:57.020 --> 00:05:59.000
قامت مجموعة من بالعلماء بصنع جهاز,

00:05:59.000 --> 00:06:01.920
استطاع إعادة تجربة حازت على نوبل في 2001

00:06:01.920 --> 00:06:05.400
تعلم عمل تجربة كسبت جائزة نوبل في ساعة واحدة

00:06:05.400 --> 00:06:07.260
مرة ثانية خالص

00:06:07.260 --> 00:06:08.460
الحواسيب أيضا بارعة في الرياضيات

00:06:08.460 --> 00:06:10.600
لا يقتصر الأمر على الحسابات بل يشمل الإثباتات

00:06:10.600 --> 00:06:14.040
طلعلك إثبات انه القانون ده مش بس صح دلوقتي 
ده هيفضل صح مدى الحياة!

00:06:14.040 --> 00:06:16.300
مثل قانون فيثاغروس له إثبات رياضي.

00:06:16.420 --> 00:06:17.540
حتى الفانين لم يسلموا!

00:06:17.540 --> 00:06:19.640
دي مثلا لوحة للفنان "The painting fool"

00:06:19.640 --> 00:06:21.555
زي ما عمل الفنان سلفادور دالي و رينيه ماغريت

00:06:21.560 --> 00:06:23.260
لما عملوا السيريالية "الفواقعية"

00:06:23.260 --> 00:06:24.820
باولو بيكاسو في التكعيبية

00:06:24.820 --> 00:06:28.060
شبكة الأعصاب التي صممتها غوغل انشأت مدرسة جديدة

00:06:28.060 --> 00:06:28.860
و اسمتها بال "Inceptionisim"

00:06:28.860 --> 00:06:29.900
فن جديد

00:06:29.900 --> 00:06:32.680
طريقة في الوصف مختلفة عما كان يراه الناس من قبل

00:06:32.680 --> 00:06:34.840
و هنا برامج تبدع الموسيقى,
و تقوم بنشرها بالمجان على الشبكة

00:06:34.840 --> 00:06:36.160
كان نفسي اعمل زي CGPGrey

00:06:36.160 --> 00:06:38.780
و احكيلك انه الموسيقى اللي ورا دي (موسيقى مرافقة)
كانت موسيقى حاسوب صممها

00:06:38.780 --> 00:06:40.120
بس يعني مش عامل كده 
ما هو حر بقى!

00:06:40.120 --> 00:06:42.400
يلخص أننا أذكياء أوي أو أغبياء أوي

00:06:42.580 --> 00:06:44.820
قدرنا نصنع اجهز أذكى منا بمراحل

00:06:44.820 --> 00:06:46.400
و السؤال الذي طرح نفسه دائما

00:06:46.400 --> 00:06:49.280
هل باستطاعة الأجهزة هذه في يوم من الأيام 
الاستحواذ على وظائفنا اكثر

00:06:49.280 --> 00:06:51.200
و تنعدم علينا الوظائف اكثر من انعدامها ألأن!

00:06:51.200 --> 00:06:54.260
يمكن الأسوأ, ممكن يثوروا علينا و يطالبوا بحقوقهم!

00:06:54.260 --> 00:06:58.060
و من يعلم؟! يمكن أن يفعلوا بنا كما فعلنا في الحيوانات

00:06:58.060 --> 00:07:00.060
الذين يفترض انهم أقل ذكاءا منا!

00:07:00.200 --> 00:07:03.220
الذي جعلنا نسيطر عليهم و نحولهم إلى مواشي!

00:07:03.380 --> 00:07:04.860
هل من المعقول أن نتحول نحن أيضا إلى مواشي!

00:07:05.000 --> 00:07:06.920
والله الحقيقة أننا لا نعلم

00:07:06.920 --> 00:07:08.640
لكننا نسيطر نوعا ما

00:07:08.720 --> 00:07:09.800
بس لو في نصيحة

00:07:09.880 --> 00:07:11.120
و أنا صراحتا لا احب جو النصح

00:07:11.120 --> 00:07:12.960
او صراحتا احبه لكن لا أجده كافيا

00:07:12.960 --> 00:07:15.780
المهم يعني ,نصيحتي لك خليك كسول!

00:07:15.780 --> 00:07:16.320
اه!

00:07:16.320 --> 00:07:18.980
لو تفكر في خطة في المستقبل حاول تعلم البرمجة

00:07:18.980 --> 00:07:20.280
خليك صانع

00:07:20.440 --> 00:07:23.900
ليه تعمل حاجة ايدك بدل ما يمكن  تبرمج روبوت ممكن يعملها

00:07:23.900 --> 00:07:25.180
خليك كسول

00:07:25.180 --> 00:07:27.120
العصراللي جاي مش بتاع الناس النشيطة!

00:07:27.300 --> 00:07:28.620
بتاع المبرمجين الكسالى

00:07:28.620 --> 00:07:30.640
او اعمل حاجة لا يمكن روبوت يقدر عملها

00:07:31.120 --> 00:07:34.300
اعمل برنامج سطحي و قول عنه برنامج علمي
مثلا يعني!

00:07:34.840 --> 00:07:38.300
دي حاجة لا يمكن للروبوت يعمل...ها

00:07:48.660 --> 00:07:49.660
 

00:07:50.465 --> 00:07:53.795
 

00:07:55.095 --> 00:07:57.705
 

